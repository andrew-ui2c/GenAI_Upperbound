{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "919b17d5-737d-4376-9af5-97cb7320ac27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Evaluate\n",
    "One of the most important steps in preparing Agents is setting a good evaluation framework. Foundation models change. Frameworks change. Data changes. Having a good set of benchmarks to evaluate against serves as both a regression test, and a benchmark upon which to improve through prompt engineering of your agents and tools, working on your data, and testing different foundation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52e8c626-8524-4e20-b059-48da32162d05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-agents databricks-langchain langgraph==0.3.4 \n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "064be851-fc55-47b1-8cfe-f7164367721e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "catalog = config['catalog']\n",
    "schema = config['schema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5546b10a-f24f-4567-a759-f5fc815d3de4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "data = [\n",
    "    Row(\n",
    "        request=\"What are the top 3 campaigns by opens?\",\n",
    "        expected_facts=[\n",
    "            \"Warm Hearts, Warm Plates (campaign_id: 120) with 1,071 opens\",\n",
    "            \"Conquer the Kitchen (campaign_id: 149) with 997 opens\",\n",
    "            \"Dive into Wealth (campaign_id: 137) with 909 opens\"\n",
    "        ],\n",
    "        guidelines=[\n",
    "            \"The response must be concise and include three campaigns\"\n",
    "        ]\n",
    "    ),\n",
    "    Row(\n",
    "        request=\"What is the cost of all the campaigns between January and February 2024?\",\n",
    "        expected_facts=[\n",
    "            \"Based on the data provided, the total cost of all campaigns between January and February 2024 is $17,383.80.\"\n",
    "        ],\n",
    "        guidelines=[\n",
    "            \"The response should say `based on the data provided`\"\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "\n",
    "spark.createDataFrame(data).write.mode(\"overwrite\").saveAsTable(f\"shm.marketing.agent_evals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c1e4e85-2bd0-46d3-b0f3-7d6ed116b675",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "retrieval_records = spark.sql(\n",
    "    \"SELECT CAST(campaign_id AS STRING) AS doc_uri, campaign_description AS content FROM shm.marketing.campaigns_fixed\"\n",
    ")\n",
    "display(retrieval_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffdc46e7-51de-4829-88c1-e156ec8135cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from databricks.agents.evals import generate_evals_df\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "agent_description = \"\"\"\n",
    "The Agent is a creative marketing generator that uses previous campaigns to generate new and novel campaigns. It is specifically designed to generate marketing campaigns that are both creative and tailored to cusomter personas.\n",
    "\"\"\"\n",
    "\n",
    "question_guidelines = \"\"\"\n",
    "# Example questions\n",
    "- Generate a new premium campaign for Viking refrigerators emphasizing durability, advanced lighting, and air purification for customers upgrading their kitchen.\n",
    "- Design a campaign for the Nest Protect 2nd Generation tailored to tech-savvy homeowners.\n",
    "\n",
    "# Additional Guidelines\n",
    "- The answer should be a generated campaign slogan\n",
    "- The expected facts should be as concise as possible\n",
    "\"\"\"\n",
    "\n",
    "evals = generate_evals_df(\n",
    "    retrieval_records,\n",
    "    num_evals=10,\n",
    "    agent_description=agent_description,\n",
    "    question_guidelines=question_guidelines\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bf20a8f-a15d-4b69-808f-27b9cfe416f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ebb2fb5-117c-42a0-96d1-a948a64e7ff8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(evals).write.mode(\"overwrite\").saveAsTable(\"shm.marketing.synthetic_evals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c63b3f5-d3c5-43fa-b499-30dfe429f9eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT slice(expected_facts, 1, 3) FROM shm.marketing.synthetic_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf1cdbb8-5668-413d-8ae7-a1023fc1a684",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE shm.marketing.combined_evals\n",
    "AS\n",
    "SELECT \n",
    "    request.messages[0].content AS request, \n",
    "    slice(expected_facts, 1, 3) AS expected_facts, \n",
    "    array('') AS guidelines \n",
    "FROM \n",
    "    shm.marketing.synthetic_evals\n",
    "UNION\n",
    "SELECT \n",
    "    request, \n",
    "    expected_facts, \n",
    "    guidelines \n",
    "FROM \n",
    "    shm.marketing.agent_evals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "470d8317-a3e1-4520-9290-c4a9830c361c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now we are going to evaluate the synthetic data set, as well as our SME developed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "517b6a53-7a62-42cb-a85c-b6f72f3647b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eval_set = spark.table(\"shm.marketing.combined_evals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f40dcadc-ccd9-44f9-a620-b02e1f3ca4f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"agent_eval\") as run:\n",
    "  mlflow.evaluate(\n",
    "    data=eval_set,\n",
    "    model='models:/shm.marketing.genie_agent/4',\n",
    "    model_type=\"databricks-agent\"\n",
    "  )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 457628674480169,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "04_evaluate",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
